{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1606763201986
    }
   },
   "outputs": [],
   "source": [
    "# create workspace\n",
    "# azureml-core of version 1.0.72 or higher is required\n",
    "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
    "from azureml.core import Workspace, Dataset, Datastore, ScriptRunConfig\n",
    "from azureml.data.data_reference import DataReference\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1606773079458
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\n",
    "from azureml.core import Environment\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "#Retrieve an already attached Azure Machine Learning Compute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "aml_compute_target = \"cpu-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(aml_compute_target))\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new compute target: {}\".format(aml_compute_target))\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 0, \n",
    "                                                                max_nodes = 1)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# get datasets from CI\n",
    "# Ad hoc Datasets also referred to Saved datasets are not discoverable from Audience Insights currently.\n",
    "# Example: IncompatibleDataset = Dataset.Tabular.from_delimited_files('https://cidatasets.blob.core.windows.net/hotel-scenario/ContosoHotel_HotelActivity_1.csv')\n",
    "# You need to use registered datasets and then consume them by their name \n",
    "# Example: CompatibleDataset = Dataset.get_by_name(ws, name='Hotel Stay Activity Data')\n",
    "\n",
    "customer_dataset = Dataset.get_by_name(ws, name='CustomerData')\n",
    "customer_pipeline_param = PipelineParameter(name=\"Customer_pipeline_param\", default_value=customer_dataset)\n",
    "customer_ds_consumption = DatasetConsumptionConfig(\"customer_dataset\", customer_pipeline_param)\n",
    "\n",
    "\n",
    "OutputPathParameter = PipelineParameter(name=\"output_path\", default_value=\"LeaseRenewalPredictionOutput4/LeaseRenewalPredictionOutput4.csv\")\n",
    "OutputDatastoreParameter = PipelineParameter(name=\"output_datastore\", default_value=\"workspaceblobstore\")\n",
    "\n",
    "env = Environment.from_conda_specification(name = 'env', file_path = './InferencePipeline.yml')\n",
    "\n",
    "# source_directory\n",
    "source_directory = './scripts'\n",
    "os.makedirs(source_directory, exist_ok=True)\n",
    "script_name = \"score.py\"\n",
    "# define a single step pipeline for demonstration purpose.\n",
    "src = ScriptRunConfig(source_directory=source_directory,\n",
    "                    script=script_name,\n",
    "                    compute_target=aml_compute_target,\n",
    "                    environment=env)\n",
    "\n",
    "inferenceStep = PythonScriptStep(\n",
    "    name=\"Inferencing_Step\",\n",
    "    script_name=src.script,\n",
    "    #arguments=[\"--input_data1\", customer_ds_consumption,\"--input_data2\", resident1_ds_consumption,\"--input_data3\", resident2_ds_consumption, \"--input_data4\", lease_ds_consumption, \"--input_data5\",payment_ds_consumption,\"--input_data6\", survey_ds_consumption,\"--input_data7\", workorder_ds_consumption, \"--output_path\", OutputPathParameter, \"--output_datastore\", OutputDatastoreParameter],\n",
    "    arguments=[\"--input_data1\", customer_ds_consumption, \"--output_path\", OutputPathParameter, \"--output_datastore\", OutputDatastoreParameter],\n",
    "    #inputs=[customer_ds_consumption, resident1_ds_consumption, resident2_ds_consumption, lease_ds_consumption, payment_ds_consumption,survey_ds_consumption,workorder_ds_consumption], \n",
    "    inputs=[customer_ds_consumption], \n",
    "    #compute_target=aml_compute_target, \n",
    "    source_directory=src.source_directory,\n",
    "    runconfig = src.run_config)\n",
    "\n",
    "print(\"Inferencing_Step created\")\n",
    "# build and validate Pipeline\n",
    "pipeline = Pipeline(workspace=ws, steps=[inferenceStep])\n",
    "print(\"Pipeline is built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "endpoint_name = 'LeaseRenewalPipelineEndpoint'\n",
    "endpoints_available = PipelineEndpoint.list(ws, active_only=False)\n",
    "for i in endpoints_available:\n",
    "    if i.name == endpoint_name:\n",
    "        print(i.name)\n",
    "        i.disable()\n",
    "        i.archive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1606773092349
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# publish pipeline endpoint\n",
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "pipeline_endpoint = PipelineEndpoint.publish(workspace=ws, name=\"LeaseRenewalPipelineEndpoint\", pipeline=pipeline, description=\"Lease Renewal Pipeline Endpoint\")\n",
    "#published_pipeline = pipeline.publish(name=\"LeaseRenewalPipeline\", description=\"published pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_endpoint = PipelineEndpoint.get(workspace=ws, name=\"LeaseRenewalPipeline\") \n",
    "# pipeline_endpoint.add_default(pipeline=published_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1606773094817
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "pipeline_endpoint = PipelineEndpoint.get(workspace=ws, name=\"LeaseRenewalPipelineEndpoint\")\n",
    "experiment = Experiment(ws, 'Lease-Renewal-Exp_Inference')\n",
    "pipeline_run = experiment.submit(config=pipeline_endpoint)\n",
    "pipeline_run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
